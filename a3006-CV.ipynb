{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE 50 of 4000\n",
      "\n",
      "CASE 100 of 4000\n",
      "\n",
      "CASE 150 of 4000\n",
      "\n",
      "CASE 200 of 4000\n",
      "\n",
      "CASE 250 of 4000\n",
      "\n",
      "CASE 300 of 4000\n",
      "\n",
      "CASE 350 of 4000\n",
      "\n",
      "CASE 400 of 4000\n",
      "\n",
      "CASE 450 of 4000\n",
      "\n",
      "CASE 500 of 4000\n",
      "\n",
      "CASE 550 of 4000\n",
      "\n",
      "CASE 600 of 4000\n",
      "\n",
      "CASE 650 of 4000\n",
      "\n",
      "CASE 700 of 4000\n",
      "\n",
      "CASE 750 of 4000\n",
      "\n",
      "CASE 800 of 4000\n",
      "\n",
      "CASE 850 of 4000\n",
      "\n",
      "CASE 900 of 4000\n",
      "\n",
      "CASE 950 of 4000\n",
      "\n",
      "CASE 1000 of 4000\n",
      "\n",
      "CASE 1050 of 4000\n",
      "\n",
      "CASE 1100 of 4000\n",
      "\n",
      "CASE 1150 of 4000\n",
      "\n",
      "CASE 1200 of 4000\n",
      "\n",
      "CASE 1250 of 4000\n",
      "\n",
      "CASE 1300 of 4000\n",
      "\n",
      "CASE 1350 of 4000\n",
      "\n",
      "CASE 1400 of 4000\n",
      "\n",
      "CASE 1450 of 4000\n",
      "\n",
      "CASE 1500 of 4000\n",
      "\n",
      "CASE 1550 of 4000\n",
      "\n",
      "CASE 1600 of 4000\n",
      "\n",
      "CASE 1650 of 4000\n",
      "\n",
      "CASE 1700 of 4000\n",
      "\n",
      "CASE 1750 of 4000\n",
      "\n",
      "CASE 1800 of 4000\n",
      "\n",
      "CASE 1850 of 4000\n",
      "\n",
      "CASE 1900 of 4000\n",
      "\n",
      "CASE 1950 of 4000\n",
      "\n",
      "CASE 2000 of 4000\n",
      "\n",
      "CASE 2050 of 4000\n",
      "\n",
      "CASE 2100 of 4000\n",
      "\n",
      "CASE 2150 of 4000\n",
      "\n",
      "CASE 2200 of 4000\n",
      "\n",
      "CASE 2250 of 4000\n",
      "\n",
      "CASE 2300 of 4000\n",
      "\n",
      "CASE 2350 of 4000\n",
      "\n",
      "CASE 2400 of 4000\n",
      "\n",
      "CASE 2450 of 4000\n",
      "\n",
      "CASE 2500 of 4000\n",
      "\n",
      "CASE 2550 of 4000\n",
      "\n",
      "CASE 2600 of 4000\n",
      "\n",
      "CASE 2650 of 4000\n",
      "\n",
      "CASE 2700 of 4000\n",
      "\n",
      "CASE 2750 of 4000\n",
      "\n",
      "CASE 2800 of 4000\n",
      "\n",
      "CASE 2850 of 4000\n",
      "\n",
      "CASE 2900 of 4000\n",
      "\n",
      "CASE 2950 of 4000\n",
      "\n",
      "CASE 3000 of 4000\n",
      "\n",
      "CASE 3050 of 4000\n",
      "\n",
      "CASE 3100 of 4000\n",
      "\n",
      "CASE 3150 of 4000\n",
      "\n",
      "CASE 3200 of 4000\n",
      "\n",
      "CASE 3250 of 4000\n",
      "\n",
      "CASE 3300 of 4000\n",
      "\n",
      "CASE 3350 of 4000\n",
      "\n",
      "CASE 3400 of 4000\n",
      "\n",
      "CASE 3450 of 4000\n",
      "\n",
      "CASE 3500 of 4000\n",
      "\n",
      "CASE 3550 of 4000\n",
      "\n",
      "CASE 3600 of 4000\n",
      "\n",
      "CASE 3650 of 4000\n",
      "\n",
      "CASE 3700 of 4000\n",
      "\n",
      "CASE 3750 of 4000\n",
      "\n",
      "CASE 3800 of 4000\n",
      "\n",
      "CASE 3850 of 4000\n",
      "\n",
      "CASE 3900 of 4000\n",
      "\n",
      "CASE 3950 of 4000\n",
      "\n",
      "CASE 4000 of 4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd       \n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Open Trining File\n",
    "os.chdir(\"/temp/DocumentCorpus/ECHR/echr_dataset-master/echr_dataset-master/document_crawler/IN/\")\n",
    "train = pd.read_csv(\"TRAIN_classifiedFULL_NOADMISS.tsv\", header=0, delimiter=\"^\", quoting=3)\n",
    "test  = pd.read_csv(\"TEST_NOclassifiedFULL_NOADMISS.tsv\", header=0, delimiter=\"^\", quoting=3)\n",
    "\n",
    "os.chdir(\"/temp/DocumentCorpus/ECHR/echr_dataset-master/echr_dataset-master/document_crawler/OUT/AV3/CV/\")\n",
    "\n",
    "train.shape\n",
    "test.shape\n",
    "\n",
    "train.columns.values\n",
    "\n",
    "from bs4 import BeautifulSoup   \n",
    "import re\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    \n",
    "    # 5a. Remove extra Stop words\n",
    "    moreStopwords = [\"b\",\"full\",\"value\",\"file\",\"period\",\"months\",\"additional\",\"basis\",\"street\",\"respect\",\"cases\",\"application\",\"amount\",\"since\",\"costs\",\"address\",\"well\",\"days\",\"series\",\"c\",\"particular\",\"purposes\",\"purpose\",\"proceedings\",\"proceeding\",\"h\",\"able\",\"ba\",\"country\",\"held\",\"board\",\"first\",\"second\",\"final\",\"judge\",\"non\",\"statement\",\"documents\",\"many\",\"notes\",\"note\",\"j\",\"considered\",\"aw\",\"echr\",\"whether\",\"language\",\"ill\",\"time\",\"taken\",\"kh\",\"rovd\",\"must\",\"set\",\"within\",\"p\",\"mr\",\"mrs\",\"provided\",\"sher\",\"one\",\"new\",\"route\",\"routes\",\"three\",\"would\",\"previously\",\"shall\",\"en\",\"k\",\"g\",\"applicants\",\"eur\",\"date\",\"might\",\"paragraph\",\"u\",\"kd\",\"could\",\"made\",\"company\",\"see\",\"public\",\"parking\",\"statements\",\"article\",\"government\",\"business\",\"information\",\"therefore\",\"right\",\"also\",\"applicant\",\"court\",\"act\",\"state\",\"security\",\"section\",\"hearing\",\"v\",\"service\",\"case\",\"law\",\"person\",\"courts\",\"regional\",\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\"]\n",
    "    more_meaningful_words = [token for token in meaningful_words if token not in moreStopwords]\n",
    "    \n",
    "    #\n",
    "    # 6. Stemmer\n",
    "    #stemmed=[]\n",
    "    #stemmer = PorterStemmer()\n",
    "    #for word in more_meaningful_words:\n",
    "    #    stemmed.append(stemmer.stem(word))\n",
    "        \n",
    "    #\n",
    "    # 7. Lemmatizer\n",
    "    Lemmatized=[]\n",
    "    Lemmatizer = WordNetLemmatizer()\n",
    "    for word in more_meaningful_words:\n",
    "        Lemmatized.append(Lemmatizer.lemmatize(word))\n",
    "        \n",
    "    #\n",
    "    # 8. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( Lemmatized ))  \n",
    "    #return( \" \".join( stemmed ))  \n",
    "    #return( \" \".join( more_meaningful_words ))  \n",
    "    #return( \" \".join( meaningful_words ))   \n",
    "    \n",
    "# Get the number of cases based on the dataframe column size\n",
    "\n",
    "num_reviews = train[\"sentences\"].size\n",
    "\n",
    "# Initialize an empty list to hold the clean cases\n",
    "clean_train_sentences = []\n",
    "\n",
    "# Loop over each case \n",
    "for i in xrange( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 100, print a message\n",
    "    if( (i+1)%50 == 0 ):\n",
    "        print \"CASE %d of %d\\n\" % ( i+1, num_reviews )                                                                    \n",
    "    clean_train_sentences.append( review_to_words( train[\"sentences\"][i] ))    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000L, 485L)\n",
      "[u'absence', u'accepted', u'access', u'accordance', u'according', u'accordingly', u'account', u'accused', u'act', u'acting', u'action', u'activity', u'addition', u'administration', u'administrative', u'admissibility', u'admitted', u'affair', u'aid', u'alia', u'allegation', u'allegedly', u'allowed', u'already', u'although', u'amended', u'among', u'andr', u'another', u'appealed', u'appear', u'appears', u'applicable', u'application', u'applied', u'apply', u'appointed', u'appropriate', u'area', u'argued', u'argument', u'arrest', u'arrested', u'article', u'asked', u'assessment', u'assistance', u'authorised', u'authority', u'available', u'awarded', u'back', u'based', u'became', u'body', u'breach', u'brought', u'called', u'cannot', u'carried', u'carry', u'cassation', u'caused', u'centre', u'certain', u'challenged', u'charge', u'charged', u'city', u'civil', u'claim', u'claimed', u'co', u'code', u'commission', u'committed', u'committee', u'communicated', u'compensation', u'competent', u'complaint', u'compliance', u'comply', u'concern', u'concerned', u'concerning', u'concluded', u'conclusion', u'condition', u'conduct', u'conducted', u'confirmed', u'connection', u'consequence', u'consider', u'consideration', u'considers', u'constitution', u'constitutional', u'contained', u'contested', u'continue', u'continued', u'contrary', u'control', u'convicted', u'conviction', u'copy', u'council', u'counsel', u'course', u'crime', u'criminal', u'custody', u'damage', u'dated', u'day', u'de', u'decide', u'declared', u'defence', u'defendant', u'degrading', u'delay', u'delivered', u'denied', u'department', u'deprived', u'deputy', u'described', u'despite', u'detail', u'detained', u'detention', u'determination', u'different', u'dismissed', u'district', u'due', u'duty', u'early', u'effect', u'effective', u'eight', u'either', u'end', u'enforcement', u'ensure', u'entered', u'entitled', u'establish', u'established', u'even', u'event', u'every', u'everyone', u'evidence', u'examination', u'examine', u'examined', u'except', u'execution', u'exercise', u'expert', u'extended', u'facility', u'failed', u'failure', u'fair', u'fall', u'family', u'far', u'federal', u'federation', u'fifth', u'filed', u'find', u'finding', u'five', u'force', u'foreign', u'form', u'former', u'found', u'founded', u'four', u'fourth', u'furthermore', u'gave', u'general', u'give', u'given', u'good', u'grant', u'granted', u'ground', u'group', u'guarantee', u'guilty', u'hajiyev', u'hand', u'head', u'health', u'heard', u'hearing', u'high', u'holding', u'home', u'hospital', u'hour', u'house', u'however', u'iii', u'immediately', u'imposed', u'imprisonment', u'inadmissible', u'included', u'including', u'incompatible', u'indicated', u'individual', u'informed', u'inhuman', u'injury', u'instance', u'instituted', u'institution', u'inter', u'interest', u'international', u'investigation', u'investigator', u'involved', u'issue', u'issued', u'judicial', u'jurisdiction', u'justice', u'justified', u'khanlar', u'lack', u'laid', u'last', u'later', u'latter', u'law', u'lawful', u'lawyer', u'least', u'leave', u'left', u'legal', u'legislation', u'length', u'letter', u'level', u'light', u'limit', u'limited', u'list', u'live', u'local', u'long', u'longer', u'lower', u'maintained', u'make', u'making', u'manner', u'material', u'matter', u'mean', u'measure', u'medical', u'member', u'mentioned', u'merit', u'ministry', u'month', u'moreover', u'name', u'namely', u'natural', u'nature', u'necessary', u'need', u'neither', u'never', u'nielsen', u'no', u'noted', u'notice', u'number', u'numerous', u'objection', u'obligation', u'observation', u'observed', u'obtain', u'obtained', u'occasion', u'offence', u'office', u'officer', u'official', u'open', u'opened', u'opinion', u'order', u'ordered', u'organisation', u'others', u'outside', u'paid', u'paragraph', u'part', u'particularly', u'party', u'pay', u'payment', u'pecuniary', u'penalty', u'pending', u'people', u'person', u'personal', u'physical', u'place', u'placed', u'point', u'pointed', u'police', u'position', u'possession', u'possibility', u'possible', u'power', u'practice', u'practising', u'pre', u'preliminary', u'prescribed', u'presence', u'present', u'prevent', u'prevention', u'previous', u'principle', u'prior', u'prison', u'procedural', u'property', u'prosecution', u'prosecutor', u'protocol', u'provide', u'provides', u'provision', u'punishment', u'pursuant', u'put', u'quashed', u'question', u'questioned', u'reason', u'reasonable', u'receive', u'received', u'record', u'reference', u'referred', u'referring', u'refusal', u'refused', u'regard', u'regarding', u'region', u'rejected', u'related', u'relating', u'relation', u'release', u'released', u'relied', u'relying', u'remained', u'remedy', u'remitted', u'ren', u'reply', u'report', u'representative', u'republic', u'request', u'requested', u'required', u'requirement', u'respectively', u'responsibility', u'responsible', u'result', u'returned', u'review', u'risk', u'rule', u'ruling', u'russia', u'russian', u'said', u'secure', u'seeking', u'seen', u'sent', u'sentence', u'sentenced', u'separate', u'serious', u'served', u'seven', u'several', u'similar', u'situation', u'six', u'social', u'society', u'sought', u'special', u'specific', u'started', u'state', u'stated', u'stating', u'status', u'still', u'subjected', u'submission', u'submit', u'submitted', u'subsequent', u'subsequently', u'suffered', u'sufficient', u'support', u'supreme', u'suspended', u'suspicion', u'system', u'take', u'taking', u'ten', u'term', u'third', u'thus', u'time', u'together', u'took', u'torture', u'town', u'transferred', u'treated', u'treatment', u'trial', u'tribunal', u'twenty', u'two', u'unable', u'unlawful', u'unspecified', u'upheld', u'upon', u'use', u'used', u'various', u'victim', u'view', u'violated', u'way', u'whose', u'without', u'witness', u'work', u'written', u'year', u'yet']\n",
      "51.3403745596 absence\n",
      "32.243940156 accepted\n",
      "65.5069100136 access\n",
      "85.6958968245 accordance\n",
      "124.64309921 according\n",
      "32.1932426263 accordingly\n",
      "88.9786705724 account\n",
      "93.6109454718 accused\n",
      "45.7212297557 act\n",
      "36.4238521856 acting\n",
      "118.254658752 action\n",
      "64.3567231394 activity\n",
      "36.1081681837 addition\n",
      "55.1736216637 administration\n",
      "172.35393512 administrative\n",
      "74.0737331226 admissibility\n",
      "29.5012110714 admitted\n",
      "44.8237693066 affair\n",
      "43.1706284969 aid\n",
      "63.6187503011 alia\n",
      "63.1731252948 allegation\n",
      "38.83263631 allegedly\n",
      "62.467782026 allowed\n",
      "46.9128928062 already\n",
      "35.5497871617 although\n",
      "37.8188640617 amended\n",
      "28.9736595983 among\n",
      "32.5691326325 andr\n",
      "77.5804342704 another\n",
      "82.1300262609 appealed\n",
      "51.5502988917 appear\n",
      "41.1691186072 appears\n",
      "43.3643743364 applicable\n",
      "76.6855917128 application\n",
      "57.489835872 applied\n",
      "37.4253637245 apply\n",
      "44.7116580829 appointed\n",
      "40.8528125267 appropriate\n",
      "47.7440989937 area\n",
      "51.9915907646 argued\n",
      "63.1839581423 argument\n",
      "90.7985527285 arrest\n",
      "61.0245376241 arrested\n",
      "78.3597705035 article\n",
      "68.4943324917 asked\n",
      "43.3876325777 assessment\n",
      "56.9086173226 assistance\n",
      "32.6789079751 authorised\n",
      "199.857427924 authority\n",
      "43.5076681386 available\n",
      "73.535859409 awarded\n",
      "44.8479146672 back\n",
      "52.7446478244 based\n",
      "56.7997592782 became\n",
      "70.7137124135 body\n",
      "60.9381240465 breach\n",
      "73.009140804 brought\n",
      "35.5601263975 called\n",
      "39.9643600124 cannot\n",
      "53.5850116664 carried\n",
      "29.2226147612 carry\n",
      "120.518386657 cassation\n",
      "55.89799527 caused\n",
      "82.2448886171 centre\n",
      "53.906299781 certain\n",
      "33.1253350156 challenged\n",
      "93.3434447221 charge\n",
      "62.0561016952 charged\n",
      "78.6246526115 city\n",
      "172.187199057 civil\n",
      "168.222744006 claim\n",
      "54.9565030026 claimed\n",
      "54.8963358371 co\n",
      "168.027131285 code\n",
      "70.7410555999 commission\n",
      "81.3112297078 committed\n",
      "54.3106868324 committee\n",
      "36.9345048354 communicated\n",
      "140.651367089 compensation\n",
      "43.7853943499 competent\n",
      "184.263374816 complaint\n",
      "26.1085904071 compliance\n",
      "33.6738000023 comply\n",
      "27.3693160788 concern\n",
      "60.1295062936 concerned\n",
      "120.63652824 concerning\n",
      "52.7200343741 concluded\n",
      "39.5163097074 conclusion\n",
      "122.783515913 condition\n",
      "47.2985262813 conduct\n",
      "42.3976607878 conducted\n",
      "44.5620157433 confirmed\n",
      "47.2806150395 connection\n",
      "25.849168369 consequence\n",
      "26.3834263043 consider\n",
      "62.2443563997 consideration\n",
      "39.4986942676 considers\n",
      "66.2815013291 constitution\n",
      "183.219219617 constitutional\n",
      "34.0819173365 contained\n",
      "52.1386596357 contested\n",
      "32.2940607259 continue\n",
      "40.5376483279 continued\n",
      "34.0048876412 contrary\n",
      "46.9118254002 control\n",
      "61.8448871788 convicted\n",
      "53.043900953 conviction\n",
      "51.9912803664 copy\n",
      "68.7157286246 council\n",
      "68.0253572337 counsel\n",
      "48.5229421937 course\n",
      "85.155707606 crime\n",
      "346.478781632 criminal\n",
      "94.1059022939 custody\n",
      "125.150933022 damage\n",
      "44.8204405143 dated\n",
      "83.6459829732 day\n",
      "35.9839957414 de\n",
      "32.6562793702 decide\n",
      "57.2707519865 declared\n",
      "64.9848448233 defence\n",
      "128.649542629 defendant\n",
      "39.1913072065 degrading\n",
      "50.8577781999 delay\n",
      "37.962884458 delivered\n",
      "34.18879678 denied\n",
      "79.0253045188 department\n",
      "55.9474838685 deprived\n",
      "52.3392551668 deputy\n",
      "31.3593066672 described\n",
      "27.3911984257 despite\n",
      "29.5465701048 detail\n",
      "76.0131441583 detained\n",
      "382.993615131 detention\n",
      "72.6055047477 determination\n",
      "35.1567254921 different\n",
      "114.854000049 dismissed\n",
      "290.89686575 district\n",
      "66.3557294279 due\n",
      "52.3748158173 duty\n",
      "38.8733317963 early\n",
      "47.803773903 effect\n",
      "54.0790764978 effective\n",
      "36.5353727274 eight\n",
      "31.7413411084 either\n",
      "27.7420276413 end\n",
      "166.395371081 enforcement\n",
      "37.1024184022 ensure\n",
      "42.5055165766 entered\n",
      "103.884285351 entitled\n",
      "31.7868781509 establish\n",
      "79.1394115924 established\n",
      "45.9141580048 even\n",
      "69.9072108135 event\n",
      "51.7901097916 every\n",
      "81.6712725431 everyone\n",
      "136.201030538 evidence\n",
      "124.334917731 examination\n",
      "75.9721469978 examine\n",
      "89.6591743688 examined\n",
      "50.5259464647 except\n",
      "60.1692905249 execution\n",
      "50.381058297 exercise\n",
      "126.209631726 expert\n",
      "56.5622815248 extended\n",
      "74.9074310161 facility\n",
      "78.2609434875 failed\n",
      "60.7097937392 failure\n",
      "65.9247974529 fair\n",
      "24.9799451374 fall\n",
      "99.3500656063 family\n",
      "59.3816560314 far\n",
      "83.8910441607 federal\n",
      "101.179622832 federation\n",
      "92.3579485593 fifth\n",
      "63.7188317035 filed\n",
      "39.1857181961 find\n",
      "61.0242912934 finding\n",
      "56.9105641796 five\n",
      "106.564007751 force\n",
      "49.174177698 foreign\n",
      "38.7783503524 form\n",
      "66.6486729095 former\n",
      "135.145338638 found\n",
      "30.6215342001 founded\n",
      "65.083832843 four\n",
      "92.3765523505 fourth\n",
      "33.3686890137 furthermore\n",
      "46.5955780699 gave\n",
      "111.96152934 general\n",
      "72.2339096987 give\n",
      "105.238199026 given\n",
      "36.3119634783 good\n",
      "30.8785739228 grant\n",
      "72.4980248955 granted\n",
      "115.544476807 ground\n",
      "67.8687961289 group\n",
      "29.9738493825 guarantee\n",
      "39.6149046258 guilty\n",
      "28.3796418883 hajiyev\n",
      "36.3504442024 hand\n",
      "61.5997722768 head\n",
      "90.7681338168 health\n",
      "58.4085596445 heard\n",
      "89.1134079564 hearing\n",
      "47.6747602862 high\n",
      "33.6887886984 holding\n",
      "51.9577265726 home\n",
      "102.442665245 hospital\n",
      "41.6241818488 hour\n",
      "78.6726818014 house\n",
      "104.797705927 however\n",
      "31.4430690376 iii\n",
      "30.7666906306 immediately\n",
      "47.7166866248 imposed\n",
      "79.1193822698 imprisonment\n",
      "39.2600617521 inadmissible\n",
      "28.0495273423 included\n",
      "68.1720321393 including\n",
      "44.5664748564 incompatible\n",
      "39.037561151 indicated\n",
      "67.2366272255 individual\n",
      "97.0337007797 informed\n",
      "39.1614289753 inhuman\n",
      "86.4435293886 injury\n",
      "121.231915838 instance\n",
      "62.5621889783 instituted\n",
      "41.3769442686 institution\n",
      "66.0184954024 inter\n",
      "123.127105086 interest\n",
      "80.100934988 international\n",
      "220.615309982 investigation\n",
      "108.374798742 investigator\n",
      "36.3005001534 involved\n",
      "68.6656509941 issue\n",
      "80.6718499314 issued\n",
      "82.3950668424 judicial\n",
      "62.2581360693 jurisdiction\n",
      "81.3853472665 justice\n",
      "31.6226734619 justified\n",
      "24.9212108241 khanlar\n",
      "52.1909266628 lack\n",
      "39.4886742337 laid\n",
      "27.7575430324 last\n",
      "48.2068963724 later\n",
      "49.1652473573 latter\n",
      "46.669315434 law\n",
      "40.9781323722 lawful\n",
      "124.352741782 lawyer\n",
      "31.0911289297 least\n",
      "54.7932688039 leave\n",
      "58.8630413239 left\n",
      "144.417905151 legal\n",
      "38.7440986794 legislation\n",
      "112.966246103 length\n",
      "86.9589599963 letter\n",
      "47.514841567 level\n",
      "32.6438340758 light\n",
      "65.8759979984 limit\n",
      "26.3765165796 limited\n",
      "36.8292524966 list\n",
      "33.7062436211 live\n",
      "67.5201677205 local\n",
      "36.0121315236 long\n",
      "31.4982570967 longer\n",
      "42.0578150373 lower\n",
      "37.5003507137 maintained\n",
      "43.6687350924 make\n",
      "25.0927456922 making\n",
      "31.1026802461 manner\n",
      "76.1527984998 material\n",
      "63.0213834817 matter\n",
      "46.2078316311 mean\n",
      "115.725896255 measure\n",
      "169.320093638 medical\n",
      "87.4846260203 member\n",
      "46.1120535883 mentioned\n",
      "88.6900784452 merit\n",
      "102.701924413 ministry\n",
      "37.607141128 month\n",
      "38.1990351804 moreover\n",
      "46.5588345789 name\n",
      "32.8356492469 namely\n",
      "47.2651053059 natural\n",
      "37.6500363716 nature\n",
      "84.6770314144 necessary\n",
      "47.383747142 need\n",
      "23.3193134638 neither\n",
      "31.8011037362 never\n",
      "31.5919550846 nielsen\n",
      "62.0615611596 no\n",
      "90.3767893023 noted\n",
      "65.8528638211 notice\n",
      "79.0882261762 number\n",
      "29.1915144362 numerous\n",
      "52.0360240199 objection\n",
      "88.5830043853 obligation\n",
      "38.4843090675 observation\n",
      "33.4031264225 observed\n",
      "33.2114704321 obtain\n",
      "45.4158633399 obtained\n",
      "42.7565752656 occasion\n",
      "145.210397589 offence\n",
      "177.706681675 office\n",
      "186.100567558 officer\n",
      "92.7654541979 official\n",
      "31.8714775999 open\n",
      "31.222786979 opened\n",
      "79.3695891861 opinion\n",
      "165.18859127 order\n",
      "106.262365715 ordered\n",
      "53.3929483405 organisation\n",
      "76.6756605478 others\n",
      "33.2439946972 outside\n",
      "63.7904189456 paid\n",
      "33.7228855303 paragraph\n",
      "114.909097767 part\n",
      "26.910284617 particularly\n",
      "148.390012742 party\n",
      "75.6680342488 pay\n",
      "90.3846223719 payment\n",
      "77.5758861593 pecuniary\n",
      "52.0731775057 penalty\n",
      "81.5568324115 pending\n",
      "43.3888676502 people\n",
      "106.034706797 person\n",
      "50.8756363279 personal\n",
      "37.5095238456 physical\n",
      "76.5281223023 place\n",
      "41.5146241813 placed\n",
      "65.3735295522 point\n",
      "27.0562731639 pointed\n",
      "292.408229761 police\n",
      "35.7477915235 position\n",
      "100.12795389 possession\n",
      "27.5634443281 possibility\n",
      "44.6921421063 possible\n",
      "46.5456328519 power\n",
      "72.8407057212 practice\n",
      "54.5558796648 practising\n",
      "83.0612580614 pre\n",
      "38.4119848193 preliminary\n",
      "37.3393259728 prescribed\n",
      "39.1858862197 presence\n",
      "70.9030172148 present\n",
      "30.1765163225 prevent\n",
      "28.8745313004 prevention\n",
      "41.4151683879 previous\n",
      "70.2973050287 principle\n",
      "35.1395251235 prior\n",
      "194.719286036 prison\n",
      "48.7013753703 procedural\n",
      "158.462402103 property\n",
      "58.4265578671 prosecution\n",
      "270.069139256 prosecutor\n",
      "131.766222527 protocol\n",
      "60.9523806581 provide\n",
      "80.8797472438 provides\n",
      "131.831947745 provision\n",
      "44.4937626374 punishment\n",
      "49.5310481243 pursuant\n",
      "37.942658393 put\n",
      "85.5505818121 quashed\n",
      "84.3797391579 question\n",
      "62.5239478572 questioned\n",
      "84.2761709507 reason\n",
      "115.09628244 reasonable\n",
      "34.8864910732 receive\n",
      "77.9516593163 received\n",
      "61.0685229255 record\n",
      "31.52942475 reference\n",
      "70.1595186266 referred\n",
      "27.3661457274 referring\n",
      "43.3686356587 refusal\n",
      "74.4589059356 refused\n",
      "77.1068738734 regard\n",
      "37.9706360775 regarding\n",
      "60.7565948386 region\n",
      "82.808486984 rejected\n",
      "36.3711384508 related\n",
      "30.1563777382 relating\n",
      "35.8750736019 relation\n",
      "81.7568949869 release\n",
      "49.6723689155 released\n",
      "56.8692739894 relied\n",
      "30.4869902572 relying\n",
      "33.5087887048 remained\n",
      "74.9695436051 remedy\n",
      "59.4947194464 remitted\n",
      "27.3478512615 ren\n",
      "35.3729055037 reply\n",
      "149.434280253 report\n",
      "76.5383287884 representative\n",
      "101.833516827 republic\n",
      "180.700306816 request\n",
      "98.7139958307 requested\n",
      "47.7899542003 required\n",
      "64.0064259704 requirement\n",
      "50.1340144876 respectively\n",
      "34.115173871 responsibility\n",
      "35.7571109275 responsible\n",
      "71.5089889306 result\n",
      "43.1008852154 returned\n",
      "86.477026887 review\n",
      "60.6424155444 risk\n",
      "123.755681893 rule\n",
      "53.8773148575 ruling\n",
      "115.335769901 russia\n",
      "222.810087996 russian\n",
      "41.2728611744 said\n",
      "38.882262077 secure\n",
      "46.7329765337 seeking\n",
      "34.4906665373 seen\n",
      "54.1107206635 sent\n",
      "92.6029091775 sentence\n",
      "55.5106197308 sentenced\n",
      "33.5250150318 separate\n",
      "54.1042120683 serious\n",
      "59.4113969416 served\n",
      "35.7263257486 seven\n",
      "71.6180370538 several\n",
      "38.4713750277 similar\n",
      "55.9792889445 situation\n",
      "60.8984537338 six\n",
      "87.1315989996 social\n",
      "38.3854240574 society\n",
      "40.9378023275 sought\n",
      "55.6609863363 special\n",
      "31.6761022729 specific\n",
      "34.1848562624 started\n",
      "47.406913606 state\n",
      "107.179334822 stated\n",
      "27.6985030244 stating\n",
      "48.244297505 status\n",
      "50.2336681464 still\n",
      "48.9069432347 subjected\n",
      "57.8728675913 submission\n",
      "37.1414207639 submit\n",
      "132.120354574 submitted\n",
      "33.7321715359 subsequent\n",
      "59.1055485216 subsequently\n",
      "32.1650766739 suffered\n",
      "44.8587394595 sufficient\n",
      "35.4022263871 support\n",
      "173.988547404 supreme\n",
      "42.3271001673 suspended\n",
      "48.9899891464 suspicion\n",
      "41.3991856983 system\n",
      "72.2531403873 take\n",
      "39.0083973841 taking\n",
      "43.711495747 ten\n",
      "53.1073234867 term\n",
      "90.4478097372 third\n",
      "62.1382525464 thus\n",
      "32.2019119684 time\n",
      "37.9170937636 together\n",
      "53.32980553 took\n",
      "55.4121659467 torture\n",
      "93.3151891732 town\n",
      "56.7491713763 transferred\n",
      "31.8251074907 treated\n",
      "158.572576649 treatment\n",
      "208.664653891 trial\n",
      "76.4653302704 tribunal\n",
      "35.2041271073 twenty\n",
      "145.303420355 two\n",
      "28.0481358813 unable\n",
      "60.7357335009 unlawful\n",
      "54.6345894941 unspecified\n",
      "92.326981879 upheld\n",
      "51.7760952701 upon\n",
      "80.3920521864 use\n",
      "52.0832644292 used\n",
      "45.7538349782 various\n",
      "72.4079559436 victim\n",
      "71.9688494596 view\n",
      "45.289201242 violated\n",
      "61.7972424212 way\n",
      "40.9309439979 whose\n",
      "92.2363582824 without\n",
      "127.544962411 witness\n",
      "57.886112451 work\n",
      "51.3748281824 written\n",
      "128.986440077 year\n",
      "25.048064798 yet\n",
      "Training the random forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\danny\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.97779, std: 0.01763, params: {}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "#vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "#                             ngram_range=(1, 2),  \\\n",
    "#                             tokenizer = None,    \\\n",
    "#                             preprocessor = None, \\\n",
    "#                             stop_words = None,   \\\n",
    "#                             max_features = 5000) \n",
    "\n",
    "# Initialize the \"TfidfVectorizer\" object, which is scikitlearn's tf/idf tool.\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, \\\n",
    "                             max_features=5000, \\\n",
    "                             min_df=0.2, \\\n",
    "                             stop_words=None, \\\n",
    "                             use_idf=True, \\\n",
    "                             tokenizer=None)\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features=[]\n",
    "train_data_features = vectorizer.fit_transform(clean_train_sentences)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "print(train_data_features.shape)\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag\n",
    "    \n",
    "print \"Training the random forest...\"\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#\n",
    "## Initialize a Random Forest classifier with 100 trees\n",
    "#forest = RandomForestClassifier(n_estimators = 100) \n",
    "#\n",
    "## Fit the forest to the training set, using the bag of words as \n",
    "## features and the sentiment labels as the response variable\n",
    "##\n",
    "## This may take a few minutes to run\n",
    "#forest = forest.fit( train_data_features, train[\"AV3\"] )    \n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_values = {} #{'C':[30]} # Decide which settings you want for the grid search. \n",
    "\n",
    "model_LR = GridSearchCV(RandomForestClassifier(n_estimators = 100), \n",
    "                        grid_values, \n",
    "                        scoring = 'roc_auc', cv = 20) \n",
    "\n",
    "# Try to set the scoring on what the contest is asking for. \n",
    "# The contest says scoring is for area under the ROC curve, so use this.\n",
    "                            \n",
    "model_LR.fit(train_data_features, train[\"AV3\"] ) # Fit the model.\n",
    "\n",
    "model_LR.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2348, 9)\n",
      "Cleaning and parsing the test set ECHR Cases...\n",
      "\n",
      "Case 100 of 2348\n",
      "\n",
      "Case 200 of 2348\n",
      "\n",
      "Case 300 of 2348\n",
      "\n",
      "Case 400 of 2348\n",
      "\n",
      "Case 500 of 2348\n",
      "\n",
      "Case 600 of 2348\n",
      "\n",
      "Case 700 of 2348\n",
      "\n",
      "Case 800 of 2348\n",
      "\n",
      "Case 900 of 2348\n",
      "\n",
      "Case 1000 of 2348\n",
      "\n",
      "Case 1100 of 2348\n",
      "\n",
      "Case 1200 of 2348\n",
      "\n",
      "Case 1300 of 2348\n",
      "\n",
      "Case 1400 of 2348\n",
      "\n",
      "Case 1500 of 2348\n",
      "\n",
      "Case 1600 of 2348\n",
      "\n",
      "Case 1700 of 2348\n",
      "\n",
      "Case 1800 of 2348\n",
      "\n",
      "Case 1900 of 2348\n",
      "\n",
      "Case 2000 of 2348\n",
      "\n",
      "Case 2100 of 2348\n",
      "\n",
      "Case 2200 of 2348\n",
      "\n",
      "Case 2300 of 2348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print test.shape\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"sentences\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print \"Cleaning and parsing the test set ECHR Cases...\\n\"\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 100 == 0 ):\n",
    "        print \"Case %d of %d\\n\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"sentences\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "## Use the random forest to make sentiment label predictions\n",
    "#result = forest.predict(test_data_features)\n",
    "#\n",
    "## Copy the results to a pandas dataframe with an \"id\" column and\n",
    "## a \"sentiment\" column\n",
    "#output = pd.DataFrame( data={\"title\":test[\"title\"],\"conclusion\":test[\"conclusion\"], \"AV3_Predict\":result} )\n",
    "#\n",
    "## Use pandas to write the comma-separated output file\n",
    "#output.to_csv( \"Bag_of_Words_LEMM_TFIDF_Uni.csv\", index=False, quoting=3, escapechar='\\\\', sep='^' )\n",
    "\n",
    "LR_result = model_LR.predict_proba(test_data_features)[:,1] \n",
    "#LR_output = pd.DataFrame(data={\"id\":test[\"id\"], \"AV3\":LR_result}) # Create our dataframe that will be written.\n",
    "LR_output = pd.DataFrame( data={\"title\":test[\"title\"],\"conclusion\":test[\"conclusion\"], \"AV3_Predict\":LR_result} )\n",
    "#LR_output.to_csv('Logistic_Reg_Proj2.csv', index=False, quoting=3) # Get the .csv file we will submit to Kaggle.\n",
    "LR_output.to_csv( \"A3006_TFIDF_LEMM_UNI.csv\", index=False, quoting=3, escapechar='\\\\', sep='^'  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
