{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE 50 of 4000\n",
      "\n",
      "CASE 100 of 4000\n",
      "\n",
      "CASE 150 of 4000\n",
      "\n",
      "CASE 200 of 4000\n",
      "\n",
      "CASE 250 of 4000\n",
      "\n",
      "CASE 300 of 4000\n",
      "\n",
      "CASE 350 of 4000\n",
      "\n",
      "CASE 400 of 4000\n",
      "\n",
      "CASE 450 of 4000\n",
      "\n",
      "CASE 500 of 4000\n",
      "\n",
      "CASE 550 of 4000\n",
      "\n",
      "CASE 600 of 4000\n",
      "\n",
      "CASE 650 of 4000\n",
      "\n",
      "CASE 700 of 4000\n",
      "\n",
      "CASE 750 of 4000\n",
      "\n",
      "CASE 800 of 4000\n",
      "\n",
      "CASE 850 of 4000\n",
      "\n",
      "CASE 900 of 4000\n",
      "\n",
      "CASE 950 of 4000\n",
      "\n",
      "CASE 1000 of 4000\n",
      "\n",
      "CASE 1050 of 4000\n",
      "\n",
      "CASE 1100 of 4000\n",
      "\n",
      "CASE 1150 of 4000\n",
      "\n",
      "CASE 1200 of 4000\n",
      "\n",
      "CASE 1250 of 4000\n",
      "\n",
      "CASE 1300 of 4000\n",
      "\n",
      "CASE 1350 of 4000\n",
      "\n",
      "CASE 1400 of 4000\n",
      "\n",
      "CASE 1450 of 4000\n",
      "\n",
      "CASE 1500 of 4000\n",
      "\n",
      "CASE 1550 of 4000\n",
      "\n",
      "CASE 1600 of 4000\n",
      "\n",
      "CASE 1650 of 4000\n",
      "\n",
      "CASE 1700 of 4000\n",
      "\n",
      "CASE 1750 of 4000\n",
      "\n",
      "CASE 1800 of 4000\n",
      "\n",
      "CASE 1850 of 4000\n",
      "\n",
      "CASE 1900 of 4000\n",
      "\n",
      "CASE 1950 of 4000\n",
      "\n",
      "CASE 2000 of 4000\n",
      "\n",
      "CASE 2050 of 4000\n",
      "\n",
      "CASE 2100 of 4000\n",
      "\n",
      "CASE 2150 of 4000\n",
      "\n",
      "CASE 2200 of 4000\n",
      "\n",
      "CASE 2250 of 4000\n",
      "\n",
      "CASE 2300 of 4000\n",
      "\n",
      "CASE 2350 of 4000\n",
      "\n",
      "CASE 2400 of 4000\n",
      "\n",
      "CASE 2450 of 4000\n",
      "\n",
      "CASE 2500 of 4000\n",
      "\n",
      "CASE 2550 of 4000\n",
      "\n",
      "CASE 2600 of 4000\n",
      "\n",
      "CASE 2650 of 4000\n",
      "\n",
      "CASE 2700 of 4000\n",
      "\n",
      "CASE 2750 of 4000\n",
      "\n",
      "CASE 2800 of 4000\n",
      "\n",
      "CASE 2850 of 4000\n",
      "\n",
      "CASE 2900 of 4000\n",
      "\n",
      "CASE 2950 of 4000\n",
      "\n",
      "CASE 3000 of 4000\n",
      "\n",
      "CASE 3050 of 4000\n",
      "\n",
      "CASE 3100 of 4000\n",
      "\n",
      "CASE 3150 of 4000\n",
      "\n",
      "CASE 3200 of 4000\n",
      "\n",
      "CASE 3250 of 4000\n",
      "\n",
      "CASE 3300 of 4000\n",
      "\n",
      "CASE 3350 of 4000\n",
      "\n",
      "CASE 3400 of 4000\n",
      "\n",
      "CASE 3450 of 4000\n",
      "\n",
      "CASE 3500 of 4000\n",
      "\n",
      "CASE 3550 of 4000\n",
      "\n",
      "CASE 3600 of 4000\n",
      "\n",
      "CASE 3650 of 4000\n",
      "\n",
      "CASE 3700 of 4000\n",
      "\n",
      "CASE 3750 of 4000\n",
      "\n",
      "CASE 3800 of 4000\n",
      "\n",
      "CASE 3850 of 4000\n",
      "\n",
      "CASE 3900 of 4000\n",
      "\n",
      "CASE 3950 of 4000\n",
      "\n",
      "CASE 4000 of 4000\n",
      "\n",
      "Cleaning and parsing the test set ECHR Cases...\n",
      "\n",
      "Case 100 of 2348\n",
      "\n",
      "Case 200 of 2348\n",
      "\n",
      "Case 300 of 2348\n",
      "\n",
      "Case 400 of 2348\n",
      "\n",
      "Case 500 of 2348\n",
      "\n",
      "Case 600 of 2348\n",
      "\n",
      "Case 700 of 2348\n",
      "\n",
      "Case 800 of 2348\n",
      "\n",
      "Case 900 of 2348\n",
      "\n",
      "Case 1000 of 2348\n",
      "\n",
      "Case 1100 of 2348\n",
      "\n",
      "Case 1200 of 2348\n",
      "\n",
      "Case 1300 of 2348\n",
      "\n",
      "Case 1400 of 2348\n",
      "\n",
      "Case 1500 of 2348\n",
      "\n",
      "Case 1600 of 2348\n",
      "\n",
      "Case 1700 of 2348\n",
      "\n",
      "Case 1800 of 2348\n",
      "\n",
      "Case 1900 of 2348\n",
      "\n",
      "Case 2000 of 2348\n",
      "\n",
      "Case 2100 of 2348\n",
      "\n",
      "Case 2200 of 2348\n",
      "\n",
      "Case 2300 of 2348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd       \n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Open Trining File\n",
    "os.chdir(\"/temp/DocumentCorpus/ECHR/echr_dataset-master/echr_dataset-master/document_crawler/IN/\")\n",
    "train = pd.read_csv(\"TRAIN_classifiedFULL_NOADMISS.tsv\", header=0, delimiter=\"^\", quoting=3)\n",
    "test  = pd.read_csv(\"TEST_NOclassifiedFULL_NOADMISS.tsv\", header=0, delimiter=\"^\", quoting=3)\n",
    "\n",
    "os.chdir(\"/temp/DocumentCorpus/ECHR/echr_dataset-master/echr_dataset-master/document_crawler/OUT/AV3/BernoulliNB/\")\n",
    "\n",
    "train.shape\n",
    "test.shape\n",
    "\n",
    "train.columns.values\n",
    "\n",
    "from bs4 import BeautifulSoup   \n",
    "import re\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "def review_to_words(review):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    \n",
    "    # 5a. Remove extra Stop words\n",
    "    moreStopwords = [\"b\",\"full\",\"value\",\"file\",\"period\",\"months\",\"additional\",\"basis\",\"street\",\"respect\",\"cases\",\"application\",\"amount\",\"since\",\"costs\",\"address\",\"well\",\"days\",\"series\",\"c\",\"particular\",\"purposes\",\"purpose\",\"proceedings\",\"proceeding\",\"h\",\"able\",\"ba\",\"country\",\"held\",\"board\",\"first\",\"second\",\"final\",\"judge\",\"non\",\"statement\",\"documents\",\"many\",\"notes\",\"note\",\"j\",\"considered\",\"aw\",\"echr\",\"whether\",\"language\",\"ill\",\"time\",\"taken\",\"kh\",\"rovd\",\"must\",\"set\",\"within\",\"p\",\"mr\",\"mrs\",\"provided\",\"sher\",\"one\",\"new\",\"route\",\"routes\",\"three\",\"would\",\"previously\",\"shall\",\"en\",\"k\",\"g\",\"applicants\",\"eur\",\"date\",\"might\",\"paragraph\",\"u\",\"kd\",\"could\",\"made\",\"company\",\"see\",\"public\",\"parking\",\"statements\",\"article\",\"government\",\"business\",\"information\",\"therefore\",\"right\",\"also\",\"applicant\",\"court\",\"act\",\"state\",\"security\",\"section\",\"hearing\",\"v\",\"service\",\"case\",\"law\",\"person\",\"courts\",\"regional\",\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\"]\n",
    "    more_meaningful_words = [token for token in meaningful_words if token not in moreStopwords]\n",
    "    \n",
    "    #\n",
    "    # 6. Stemmer\n",
    "    #stemmed=[]\n",
    "    #stemmer = PorterStemmer()\n",
    "    #for word in more_meaningful_words:\n",
    "    #    stemmed.append(stemmer.stem(word))\n",
    "        \n",
    "    #\n",
    "    # 7. Lemmatizer\n",
    "    Lemmatized=[]\n",
    "    Lemmatizer = WordNetLemmatizer()\n",
    "    for word in more_meaningful_words:\n",
    "        Lemmatized.append(Lemmatizer.lemmatize(word))\n",
    "        \n",
    "    #\n",
    "    # 8. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( Lemmatized ))  \n",
    "    #return( \" \".join( stemmed ))  \n",
    "    #return( \" \".join( more_meaningful_words ))  \n",
    "    #return( \" \".join( meaningful_words ))   \n",
    "    \n",
    "\n",
    "y_train = train['AV3']\n",
    "\n",
    "#traindata = []\n",
    "#for i in xrange(0,len(train['sentences'])):\n",
    "#    traindata.append(\" \".join(review_to_wordlist(train['sentences'][i])))\n",
    "\n",
    "# Initialize an empty list to hold the clean cases\n",
    "num_reviews = train[\"sentences\"].size\n",
    "traindata = []\n",
    "\n",
    "# Loop over each case \n",
    "for i in xrange( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 100, print a message\n",
    "    if( (i+1)%50 == 0 ):\n",
    "        print \"CASE %d of %d\\n\" % ( i+1, num_reviews )                                                                    \n",
    "    traindata.append( review_to_words( train[\"sentences\"][i] ))        \n",
    "    \n",
    "#testdata = []\n",
    "#for i in xrange(0,len(test['sentences'])):\n",
    "#    testdata.append(\" \".join(review_to_wordlist(test['sentences'][i])))\n",
    "num_reviews = len(test[\"sentences\"])\n",
    "testdata = [] \n",
    "\n",
    "print \"Cleaning and parsing the test set ECHR Cases...\\n\"\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 100 == 0 ):\n",
    "        print \"Case %d of %d\\n\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"sentences\"][i] )\n",
    "    testdata.append( clean_review )\n",
    "    \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#tfv = TFIV(min_df=3,  max_features=None, \n",
    "#        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "#        ngram_range=(2, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "#        stop_words = 'english')        \n",
    "tfv = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             ngram_range=(2, 2),  \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "X_all = traindata + testdata # Combine both to fit the TFIDF vectorization.\n",
    "lentrain = len(traindata)\n",
    "\n",
    "tfv.fit(X_all) # This is the slow part!\n",
    "X_all = tfv.transform(X_all)\n",
    "\n",
    "X = X_all[:lentrain] # Separate back into training and test sets. \n",
    "X_test = X_all[lentrain:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\danny\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1.0, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "grid_values = {'C':[30]} # Decide which settings you want for the grid search. \n",
    "    \n",
    "#model_LR = GridSearchCV(LR(penalty = 'L2', dual = True, random_state = 0), \n",
    "#                        grid_values, scoring = 'roc_auc', cv = 20) \n",
    "\n",
    "#model_LR = GridSearchCV(cv=20, estimator=LogisticRegression(C=1.0, class_weight=None, dual=True, \n",
    "#        fit_intercept=True, intercept_scaling=1, penalty='L2', random_state=0, tol=0.0001),\n",
    "#        fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
    "#        param_grid={'C': [30]}, pre_dispatch='2*n_jobs', refit=True,\n",
    "#        score_func=None, scoring='roc_auc', verbose=0)\n",
    "\n",
    "model_LR = GridSearchCV(LogisticRegression(penalty='l2', dual=True, tol=0.0001, \n",
    "                         C=1, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         class_weight=None, random_state=None), \n",
    "                         grid_values, scoring = 'roc_auc', cv = 20) \n",
    "\n",
    "# Try to set the scoring on what the contest is asking for. \n",
    "# The contest says scoring is for area under the ROC curve, so use this.\n",
    "                            \n",
    "model_LR.fit(X,y_train) # Fit the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.95657, std: 0.02247, params: {'C': 30}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_LR.grid_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=30, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1.0, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=30, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='L2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(C=30, class_weight=None, dual=True, fit_intercept=True, \n",
    "                   intercept_scaling=1, penalty='L2', random_state=0, tol=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multinomial Classifier\n",
    "#from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "#Binary Classifier\n",
    "from sklearn.naive_bayes import BernoulliNB as MNB\n",
    "\n",
    "\n",
    "model_NB = MNB()\n",
    "model_NB.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Fold CV Score for Multinomial Naive Bayes:  0.945183114993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# use 20-fold cross validation score with ROC_AUC to compare with Logistic Regression.\n",
    "print \"20 Fold CV Score for MNB: \", np.mean(cross_val_score (model_NB, X, y_train, cv=20, scoring='roc_auc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "sgd_params = {'alpha': [0.00006, 0.00007, 0.00008, 0.0001, 0.0005]} # Regularization parameter\n",
    "    \n",
    "model_SGD = GridSearchCV(SGDClassifier(random_state = 0, shuffle = True, loss = 'modified_huber'), sgd_params, scoring = 'roc_auc', cv = 20) # Find out which regularization parameter works the best. \n",
    "                            \n",
    "model_SGD.fit(X, y_train) # Fit the model.\n",
    "\n",
    "\n",
    "GridSearchCV(cv=20, error_score='raise',\n",
    "       estimator=LogisticRegression(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
    "          intercept_scaling=1.0, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False),\n",
    "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [30]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)\n",
    "\n",
    "model_SGD.grid_scores_\n",
    "\n",
    "LR_result = model_LR.predict_proba(X_test)[:,1] # We only need the probabilities that the movie review was a 7 or greater. \n",
    "#LR_output = pd.DataFrame(data={\"id\":test[\"id\"], \"AV3\":LR_result}) # Create our dataframe that will be written.\n",
    "LR_output = pd.DataFrame( data={\"title\":test[\"title\"],\"conclusion\":test[\"conclusion\"], \"AV3\":LR_result} )\n",
    "#LR_output.to_csv('Logistic_Reg_Proj2.csv', index=False, quoting=3) # Get the .csv file we will submit to Kaggle.\n",
    "LR_output.to_csv( \"Logistic_Reg_Proj.csv\", index=False, quoting=3, escapechar='\\\\', sep='^' )\n",
    "\n",
    "# Repeat this for Multinomial Naive Bayes\n",
    "\n",
    "MNB_result = model_NB.predict_proba(X_test)[:,1]\n",
    "MNB_output = pd.DataFrame(data={\"title\":test[\"title\"],\"conclusion\":test[\"conclusion\"], \"AV3\":MNB_result})\n",
    "#MNB_output.to_csv('MNB_Proj2.csv', index = False, quoting = 3)\n",
    "MNB_output.to_csv( \"MNB_Proj4.csv\", index=False, quoting=3, escapechar='\\\\', sep='^' )\n",
    "    \n",
    "# Last, do the Stochastic Gradient Descent model with modified Huber loss.\n",
    "    \n",
    "SGD_result = model_SGD.predict_proba(X_test)[:,1]\n",
    "SGD_output = pd.DataFrame(data={\"title\":test[\"title\"],\"conclusion\":test[\"conclusion\"], \"AV3\":SGD_result})\n",
    "#SGD_output.to_csv('SGD_Proj2.csv', index = False, quoting = 3)\n",
    "SGD_output.to_csv( \"SGD_Proj4.csv\", index=False, quoting=3, escapechar='\\\\', sep='^' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
